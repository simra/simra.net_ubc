<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <title>Vision-based FastSLAM without Odometry</title>
    <link rel="stylesheet" href="/style.css" type="text/css">
    <link rel="icon" href="http://www.cs.ubc.ca:80//images/s.png" type="image/png">
    <meta name="author" content="Robert Sim">
  </head>
<body>
<div class="header">
<h1>Vision-based FastSLAM without Odometry</h1>
<div class="lefthead">
<a href="/index.html">home</a> <a href="/contact.html">contact</a> <a href="/research.html">publications</a> <a href="/cv.html">cv</a> <a href="/software.html">software</a> 
</div>
<div class="righthead">
<a href="/blog.html">blog</a>
<a href="/koan.html">koan</a>
<a href="/simra_net.html">simra.net</a>
</div>
</div>
<br style="clear:all;">
<div class="core">    
<a href="~simra_2Flci_2Ffastslam_2F/GOOD_PART_ZOOM_4000.ppm.png"><img src="/lci/fastslam/~simra_2Flci_2Ffastslam_2F/GOOD_PART_ZOOM_4000.ppm.png" width="200" style="position: relative;float: right;margin-right: 10px;margin-bottom: 10px;
"></a>
<p>
[Update June 13, 2006]: This work received the "Best Robotics Paper"
award at Computer and Robot Vision 2006.  The paper is here:
<ul>
<li><u>Design and analysis of a framework for real-time vision-based SLAM
using
Rao-Blackwellised particle filters</u>, Robert Sim, Pantelis Elinas,
Matt Griffin, Alex Shyr, and James J. Little
<br>
Proceedings of the 3rd Canadian Conference on Computer and Robotic
Vision (CRV 2006), Quebec City, QC, 9 pages, 2006. [ <a href="/publications/sim_crv06.pdf">pdf</a> ]
</ul>
</p>
<p>
[Update Feb 9, 2006]: Our latest ICRA paper describing this work:
<ul>
<li><u>&sigma;SLAM: Stereo Vision SLAM Using the
Rao-Blackwellised Particle Filter and a Novel
Mixture Proposal Distribution</u>, Pantelis Elinas, Robert Sim, and James J. Little
<br>
Proceedings of the IEEE International Conference on Robotics and
Automation, Orlando, FL, 7 pages, 2006. [ <a href="/publications/elinas_icra06.pdf">pdf</a> ]
</p>
</ul>
[Update July 27, 2005]: Other papers describing this work:
<ul>
<li>Robert Sim, Matt Griffin, Alex Shyr, and James J. Little, <i>"Scalable
real-time vision-based SLAM for planetary rovers"</i>, Proceedings of the
IEEE IROS Workshop on Robot Vision for Space Applications, Edmonton,
AB, 6 pages, 2005. [ <a href="/publications/sim_et_al_scal_slam.pdf">pdf</a> ] 
<li> Robert Sim, Pantelis Elinas, Matt Griffin, and James J. Little, <i>"Vision-based SLAM using the Rao-Blackwellised Particle Filter"</i>,
IJCAI Workshop on Reasoning with Uncertainty in Robotics (RUR), Edinburgh, Scotland, 8 pages,
2005. [ <a href="/publications/rur05_sim.pdf">pdf</a> ]
</ul>
<p>Some map construction movies (click to view, DivX codec required for windows users: www.divx.com):
Older results below..
<table border="1">
<tr>
<td style="padding:5px;"> [Update November 11, 2005 ]: New results- Movie of SLAM using a mixture
proposal. <br>
<a href="mix.avi"><img src="/lci/fastslam/mix.png" width="200"></a>
<tr>
<td style="padding:5px;">  UBC Collaborative Robotics Lab (6
DOF, no odometry, mixture proposal distribution)<br> <a href="lci_x210_1.avi"><img src="/lci/fastslam/lci_x210_1.png" width="200"></a> [<a href="lci_x210_input_right.avi">input
sequence**</a>] </td>  
<td style="padding:5px">  UBC Laboratory for Computational Intelligence (West)
(3 DOF, using odometry)<br> <a href="iros_ws.avi"><img src="/lci/fastslam/iros_ws.png" width="200"></a> [<a href="iros_input.avi">input
sequence**</a>]</td>
</tr>
</table>
<p>
** for full stereo input sequences and calibration information, please
send me an email.. simra @ cs . ubc . ca
<p>
[Update July 21, 2005]: Much of the text below is outdated (of
course).   The key advances
in the last few months is that now we can handle six degrees of
freedom, we've implemented a mixture proposal distribution to detect
loop closure, and we have a much more robust system in general.  More
details to come. :-)
<p>
This is joint work with Pantelis Elinas, Matt Griffin, Alex Shyr and Jim Little.
 The map above was constructed using a Rao-Blackwellised particle filter
    (RBPF) with 400 particles.  The maps are 3D landmarks constructed
    from SIFT features.  The key contribution of this work is that
    where most RBPF implementations for SLAM rely on odometric
    observations for a motion model, we rely on motion estimates
    computed directly from sequential pairs of stereo images (similar
    to FastSLAM 2.0, but without taking into account *any* odometric
    information). This map consists of roughly 11,000 3D landmarks,
    associated with a subset of 38,000 SIFT features (SIFT features
    observed more than 3 times are promoted to landmarks). It should
    be evident that the robot traversed between two rooms. The
    computation finished after 4000 frames. We haven't tried smaller
    numbers of particles, and it is quite possible that the map
    quality will be just as good.  The total trajectory length is
    65.7m. The room is approximately 18m by 9m in size. Average
    compute time was 11.9s/frame.  However, for memory-related issues
    we are not using fast methods for SIFT correspondence (such as a
    kd-tree), nor have we spent much effort on optimization.
<p>
<h3>Sample Results</h3>
[Oct 25, 2005]: Here's a run where the robot successfully closes a
loop (about 30m tall), 3000 frames, using 500 particles, vision-based
odometry and a mixture proposal distribution for global localization.
<a href="~simra_2Flci_2Ffastslam_2F/corridor.jpg"><img src="/lci/fastslam/~simra_2Flci_2Ffastslam_2F/corridor.jpg" align="left" width="500"></a>
<br clear="ALL">
<h3>More Results</h3>
Legend:
<table>
<tr><td>Yellow:</td><td>Max-weight Particle trajectory</td>
<tr><td>Blue:</td><td>Robot odometer</td>
<tr><td>Pink:</td><td>Visual odometer (see below)</td>
</table>
<table border="0"> <tr valign="top"> <td><div style="margin: 20px;">
<b>Odometry</b><br> <a href="~simra_2Flci_2Ffastslam_2F/GOOD_ODO_ZOOM_4000.ppm.png"><img src="/lci/fastslam/~simra_2Flci_2Ffastslam_2F/GOOD_ODO_ZOOM_4000.ppm.png" width="200"></a><br> A map
constructed using the robot's odometry alone (for comparison purposes
only-- odometry was not used for the other maps). The start of the
trajectory is on the very left. Click to enlarge... </div></td>
<td><div style="margin: 20px;">
<b>Visual Odometry</b><br>
<a href="~simra_2Flci_2Ffastslam_2F/GOOD_MOT_ZOOM_4000.ppm.png"><img src="/lci/fastslam/~simra_2Flci_2Ffastslam_2F/GOOD_MOT_ZOOM_4000.ppm.png" width="200"></a><br> A map constructed using
    'visual odometry'-- in other words the frame-to-frame motion
    estimate. The individual motions in this estimate were used to compute the proposal
    distribution for propagating the RBPF.
</div></td> 
<td>
<div style="margin: 20px;">
<b>KEY RESULTS: RBPF Map</b><br>
<a href="~simra_2Flci_2Ffastslam_2F/GOOD_PART_ZOOM_4000.ppm.png"><img src="/lci/fastslam/~simra_2Flci_2Ffastslam_2F/GOOD_PART_ZOOM_4000.ppm.png" width="200"></a><br> The coup de grace: the
    map constructed by the RBPF (actually, the map corresponding to
    the particle with the highest weight-- there are the equivalent of
    400 maps maintained simultaneously by the RBPF.)
</div>
</td></tr>
</table>
<h2>More images...</h3>
<h3>Detail</h3>
<a href="~simra_2Flci_2Ffastslam_2F/GOOD_ZOOM_ZOOM_PART.png"><img src="/lci/fastslam/~simra_2Flci_2Ffastslam_2F/GOOD_ZOOM_ZOOM_PART.png" width="350" align="left" hspace="20px"></a><br> A detail view of part of the map.  The red
    blob is the set of particles.  The green lines indicate the
    viewing direction of the camera.  The "knots" (regions where the
    trajectory jumps around) in the yellow trajectory correspond to
    locations where the robot was rotating in place-- there is some
    bias in the translation estimate, which can be seen as slowly
    curving sections in the pink trajectory (visual-odometry), and we
    had to insert some noise into the proposal to correct for this.
<br clear="ALL">    
    <hr>
    <address>
      <a href="mailto:web@simra.net">Robert Sim</a>,
      Last modified:   13 Jun 2006
    </address>
</div>
  <center><font size="2">This is a free demo result from the <a href="http://www.waybackmachinedownloads.com">Wayback Machine</a> Downloader. It is not a complete website.</font></center></body>
</html>